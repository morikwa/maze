{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from collections import deque\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_DICT = {'S':0,' ':1,'#':2,'A':3,'B':4,'C':5,'D':6,'E':7,'G':8,'o':9}\n",
    "INV_MAZE_DICT = dict((v, k) for k, v in MAZE_DICT.items()) \n",
    "def read_maze(maze_path):\n",
    "        f = open(maze_path)\n",
    "        line = f.read()\n",
    "        f.close()\n",
    "\n",
    "        maze = line.split('\\n')\n",
    "        maze = maze[:len(maze)-1]\n",
    "        maze_num = []\n",
    "\n",
    "        for i in maze:\n",
    "            maze_num.append([MAZE_DICT[j] for j in i ])\n",
    "\n",
    "        return np.array(maze_num)\n",
    "\n",
    "maze_field = read_maze('./data/maze1.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.迷路の構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########\n",
      "#o   #   G#\n",
      "# ##   ## #\n",
      "# # o#o   #\n",
      "# # ### # #\n",
      "#S   o   o#\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "class Maze_Function(object):\n",
    "    def __init__(self,maze):\n",
    "        self.maze = maze\n",
    "        self.start_point = self.get_location(np.where(maze==0))\n",
    "        self.goal_point = self.get_location(np.where(maze==8))\n",
    "        self.item_points = self.get_location(np.where(maze==9))\n",
    "        self.enemy_a = self.get_location(np.where(maze==3))\n",
    "        self.enemy_b = self.get_location(np.where(maze==4))\n",
    "        self.enemy_c = self.get_location(np.where(maze==5))\n",
    "        self.enemy_d = self.get_location(np.where(maze==6))\n",
    "        self.enemy_e = self.get_location(np.where(maze==7))\n",
    "        self.item_num = len(self.item_points)\n",
    "        self.movable_vec = [[1,0],[-1,0],[0,1],[0,-1],[0,0]]\n",
    "        \n",
    "    def display(self):\n",
    "        for i in range(self.maze.shape[0]):\n",
    "            line = \"\"\n",
    "            for j in range(self.maze.shape[1]):\n",
    "                line += INV_MAZE_DICT[self.maze[i,j]]\n",
    "            print(line)\n",
    "            \n",
    "    def get_location(self,np_location):\n",
    "        y_ = np_location[0]\n",
    "        x_ = np_location[1]\n",
    "        location = []\n",
    "        for i in range(len(y_)):\n",
    "            location.append([y_[i],x_[i]])\n",
    "        return location\n",
    "    \n",
    "    def get_actions(self,state):\n",
    "        movables = []\n",
    "\n",
    "        for v in self.movable_vec:\n",
    "            x = state[1] + v[1]\n",
    "            y = state[0] + v[0]\n",
    "            #print(v)\n",
    "            #print([y,x])\n",
    "            \n",
    "            #print(self.maze[y,x])\n",
    "\n",
    "            if not(0 < x <= self.maze.shape[1] and\n",
    "                  0  < y <= self.maze.shape[0] and\n",
    "                  self.maze[y,x] != 2):\n",
    "                continue\n",
    "            movables.append(v)\n",
    "            #print(\"ok\")\n",
    "\n",
    "        return movables\n",
    "        \n",
    "    \n",
    "    \n",
    "    def enemy_action(self,state,count):\n",
    "        \n",
    "        if len(self.enemy_a) != 0:\n",
    "            for i in range(len(self.enemy_a)):\n",
    "                move_select = self.get_actions(self.enemy_a[i])\n",
    "                if state[0] > self.enemy_a[i][0] and [1,0] in move_select:\n",
    "                    self.enemy_a[i][0] += 1\n",
    "                    continue\n",
    "                elif state[0] < self.enemy_a[i][0] and [-1,0] in move_select:\n",
    "                    self.enemy_a[i][0] -= 1\n",
    "                    continue\n",
    "                elif state[1] > self.enemy_a[i][1] and [0,1] in move_select:\n",
    "                    self.enemy_a[i][1] += 1\n",
    "                    continue\n",
    "                elif state[1] < self.enemy_a[i][1] and [0,-1] in move_select:\n",
    "                    self.enemy_a[i][1] -= 1\n",
    "                    continue\n",
    "                else:\n",
    "                    if [-1,0] in move_select:\n",
    "                        self.enemy_a[i][0] -= 1\n",
    "                        continue\n",
    "                    elif [0,-1] in move_select:\n",
    "                        self.enemy_a[i][1] -= 1\n",
    "                        continue\n",
    "                    elif [1,0] in move_select:\n",
    "                        self.enemy_a[i][0] += 1\n",
    "                        continue\n",
    "                    elif [0,1] in move_select:\n",
    "                        self.enemy_a[i][0] += 1\n",
    "        \n",
    "        if len(self.enemy_b) != 0:\n",
    "            for i in range(len(self.enemy_b)):\n",
    "                move_select = self.get_actions(self.enemy_b[i])\n",
    "                if state[1] > self.enemy_b[i][1] and [0,1] in move_select:\n",
    "                    self.enemy_a[i][1] += 1\n",
    "                    continue\n",
    "                elif state[1] < self.enemy_b[i][1] and [0,-1] in move_select:\n",
    "                    self.enemy_a[i][1] -= 1\n",
    "                    continue\n",
    "                elif state[0] > self.enemy_b[i][1] and [1,0] in move_select:\n",
    "                    self.enemy_a[i][0] += 1\n",
    "                    continue\n",
    "                elif state[0] < self.enemy_b[i][1] and [-1,0] in move_select:\n",
    "                    self.enemy_a[i][0] -= 1\n",
    "                    continue\n",
    "                else:\n",
    "                    if [1,0] in move_select:\n",
    "                        self.enemy_b[i][0] += 1\n",
    "                        continue\n",
    "                    elif [0,-1] in move_select:\n",
    "                        self.enemy_b[i][1] -= 1\n",
    "                        continue\n",
    "                    elif [-1,0] in move_select:\n",
    "                        self.enemy_b[i][0] -= 1\n",
    "                        continue\n",
    "                    elif [0,1] in move_select:\n",
    "                        self.enemy_b[i][0] += 1  \n",
    "                    \n",
    "        if len(self.enemy_c) != 0:\n",
    "            for i in range(len(self.enemy_c)):\n",
    "                move_select = self.get_actions(self.enemy_c[i])\n",
    "                if [0,-1] in move_select:\n",
    "                    self.enemy_c[i][1] -= 1\n",
    "                    continue\n",
    "                elif [1,0] in move_select:\n",
    "                    self.enemy_c[i][0] += 1\n",
    "                    continue\n",
    "                elif [0,1] in move_select:\n",
    "                    self.enemy_c[i][1] += 1\n",
    "                    continue\n",
    "                elif [-1,0] in move_select:\n",
    "                    self.enemy_c[i][0] -= 1           \n",
    "   \n",
    "        if len(self.enemy_d) != 0:\n",
    "            for i in range(len(self.enemy_d)):\n",
    "                move_select = self.get_actions(self.enemy_d[i])\n",
    "                if [0,1] in move_select:\n",
    "                    self.enemy_d[i][1] += 1\n",
    "                    continue\n",
    "                elif [1,0] in move_select:\n",
    "                    self.enemy_d[i][0] += 1\n",
    "                    continue\n",
    "                elif [0,-1] in move_select:\n",
    "                    self.enemy_d[i][1] -= 1\n",
    "                    continue\n",
    "                elif [-1,0] in move_select:\n",
    "                    self.enemy_d[i][0] -= 1 \n",
    "\n",
    "        if len(self.enemy_e) != 0:\n",
    "            for i in range(len(self.enemy_e)):\n",
    "                move_select = self.get_actions(self.enemy_e[i])\n",
    "                if [0,1] in move_select:\n",
    "                    self.enemy_e[i][1] += 1\n",
    "                    continue\n",
    "                elif [1,0] in move_select:\n",
    "                    self.enemy_e[i][0] += 1\n",
    "                    continue\n",
    "                elif [0,1] in move_select:\n",
    "                    self.enemy_e[i][1] -= 1\n",
    "                    continue\n",
    "                elif [-1,0] in move_select:\n",
    "                    self.enemy_e[i][0] -= 1\n",
    "    \n",
    "    def get_value(self,state,action):\n",
    "        value = 0\n",
    "        done = False\n",
    "       \n",
    "        enemy_list = [self.enemy_a,self.enemy_b,self.enemy_c,self.enemy_d,self.enemy_e]\n",
    "        if state in self.item_points:\n",
    "            self.get_items(state)\n",
    "            value += 100\n",
    "        for j in enemy_list:\n",
    "            if state in j:\n",
    "                value -= 999\n",
    "                done = True\n",
    "                return value,done\n",
    "        if state in self.goal_point:\n",
    "            if len(self.item_points) == 0:\n",
    "                value += 999\n",
    "                done = True\n",
    "                #print(\"#\"*15)\n",
    "                #print(\"     Goal     \")\n",
    "                #print(\"#\"*15)\n",
    "        \n",
    "        return value,done\n",
    "            \n",
    "            \n",
    "    def get_items(self,state):\n",
    "        self.item_points.remove(state)\n",
    "        self.maze[state[0],state[1]] = 1\n",
    "        \n",
    "maze = Maze_Function(maze_field)\n",
    "maze.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0\n",
    "        self.e_decay = 0.9999\n",
    "        self.e_min = 0.01\n",
    "        self.learning_rate = 0.1\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_shape=(2,2), activation='tanh'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='tanh'))\n",
    "        model.add(Dense(64, activation='tanh'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss=\"mse\", optimizer=RMSprop(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember_memory(self, state, action, reward, next_state, next_movables, done):\n",
    "        self.memory.append((state, action, reward, next_state, next_movables, done))\n",
    "\n",
    "    def choose_action(self, state, movables):\n",
    "        if self.epsilon >= random.random():\n",
    "            return random.choice(movables)\n",
    "        else:\n",
    "            return self.choose_best_action(state, movables)\n",
    "        \n",
    "    def choose_best_action(self, state, movables):\n",
    "        best_actions = []\n",
    "        max_act_value = -1000\n",
    "        for action in movables:\n",
    "            np_action = np.array([[state, action]])\n",
    "            act_value = self.model.predict(np_action)\n",
    "            if act_value > max_act_value:\n",
    "                best_actions = [action,]\n",
    "                max_act_value = act_value\n",
    "            elif act_value == max_act_value:\n",
    "                best_actions.append(action)\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def replay_experience(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(batch_size):\n",
    "            state, action, reward, next_state, next_movables, done = minibatch[i]\n",
    "            input_action = [state, action]\n",
    "            if done:\n",
    "                target_f = reward\n",
    "            else:\n",
    "                next_rewards = []\n",
    "                for i in next_movables:\n",
    "                    np_next_s_a = np.array([[next_state, i]])\n",
    "                    next_rewards.append(self.model.predict(np_next_s_a))\n",
    "                np_n_r_max = np.amax(np.array(next_rewards))\n",
    "                target_f = reward + self.gamma * np_n_r_max\n",
    "            X.append(input_action)\n",
    "            Y.append(target_f)\n",
    "        np_X = np.array(X)\n",
    "        np_Y = np.array([Y]).T\n",
    "        self.model.fit(np_X, np_Y, epochs=10, verbose=0)\n",
    "        if self.epsilon > self.e_min:\n",
    "            self.epsilon *= self.e_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/20000, score: 400, e1.0 \t 499\n",
      "episode: 500/20000, score: 400, e0.95 \t 499\n",
      "episode: 1000/20000, score: 400, e0.9 \t 499\n",
      "episode: 1500/20000, score: 500, e0.86 \t 499\n",
      "episode: 2000/20000, score: 1499, e0.82 \t 495\n",
      "episode: 2500/20000, score: 1499, e0.78 \t 377\n",
      "episode: 3000/20000, score: 1499, e0.74 \t 249\n",
      "episode: 3500/20000, score: 400, e0.7 \t 499\n",
      "episode: 4000/20000, score: 500, e0.67 \t 499\n",
      "episode: 4500/20000, score: 400, e0.64 \t 499\n",
      "episode: 5000/20000, score: 400, e0.61 \t 499\n",
      "episode: 5500/20000, score: 400, e0.58 \t 499\n",
      "episode: 6000/20000, score: 400, e0.55 \t 499\n",
      "episode: 6500/20000, score: 500, e0.52 \t 499\n",
      "episode: 7000/20000, score: 400, e0.5 \t 499\n",
      "episode: 7500/20000, score: 1499, e0.47 \t 441\n",
      "episode: 8000/20000, score: 1499, e0.45 \t 288\n",
      "episode: 8500/20000, score: 500, e0.43 \t 499\n",
      "episode: 9000/20000, score: 500, e0.41 \t 499\n",
      "episode: 9500/20000, score: 1499, e0.39 \t 466\n",
      "episode: 10000/20000, score: 1499, e0.37 \t 390\n",
      "episode: 10500/20000, score: 500, e0.35 \t 499\n",
      "episode: 11000/20000, score: 1499, e0.33 \t 415\n"
     ]
    }
   ],
   "source": [
    "state_size = 2\n",
    "action_size = 2\n",
    "dqn_agent = DQN_Agent(state_size,action_size)\n",
    "\n",
    "episodes = 20000\n",
    "times = 500\n",
    "\n",
    "for e in range(episodes):\n",
    "    maze_field = read_maze('./data/maze1.txt')\n",
    "    maze = Maze_Function(maze_field)\n",
    "    #print(maze.maze)\n",
    "    state = maze.start_point[0]\n",
    "    score = 0\n",
    "    remain_S = 1\n",
    "    for time in range(times):\n",
    "        next_state = state.copy()\n",
    "        moveables = maze.get_actions(state)\n",
    "        action = dqn_agent.choose_action(state,moveables)\n",
    "        next_state[0] += action[0]\n",
    "        next_state[1] += action[1]\n",
    "        #print(next_state)\n",
    "        #print(state)\n",
    "        #print(maze.maze)\n",
    "\n",
    "        maze.enemy_action(state=next_state,count=time+1)\n",
    "\n",
    "        \"\"\"\n",
    "        print(maze.maze)\n",
    "        print(\"#\"*10)\n",
    "        print(state)\n",
    "        print(\"#\"*10)\n",
    "        print(\"#\"*10)\n",
    "        print(action)\n",
    "        print(\"#\"*10)\n",
    "        \"\"\"\n",
    "        reward,done = maze.get_value(state,action)\n",
    "        score += reward\n",
    "        next_movables = maze.get_actions(next_state)\n",
    "        dqn_agent.remember_memory(state,action,reward,next_state,next_movables,done)\n",
    "        maze.maze[state[0],state[1]] = remain_S\n",
    "        remain_S = maze.maze[next_state[0],next_state[1]]\n",
    "        if remain_S == 9:\n",
    "            remain_S = 1\n",
    "        maze.maze[next_state[0],next_state[1]] = 0\n",
    "        if done or time == (times - 1):\n",
    "            if e % 500 == 0:\n",
    "                print(\"episode: {}/{}, score: {}, e{:.2} \\t {}\".format(e,episodes,score,dqn_agent.epsilon,time))\n",
    "                #print(state)\n",
    "                #print(maze.enemy_a)\n",
    "                #print(maze.enemy_b)\n",
    "                #print(maze.item_points)\n",
    "                #maze.display()\n",
    "            break\n",
    "        state = next_state\n",
    "    dqn_agent.replay_experience(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
